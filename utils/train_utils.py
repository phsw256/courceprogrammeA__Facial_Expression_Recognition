import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
import time
import os
import streamlit as st
import datetime

import torchvision


def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler=None,
                num_epochs=10, device=None, save_dir='./checkpoints', recorder=None):
    """
    è®­ç»ƒæ¨¡å‹å¹¶è®°å½•æ€§èƒ½æŒ‡æ ‡

    å‚æ•°:
        model: è¦è®­ç»ƒçš„æ¨¡å‹
        train_loader, valid_loader: è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰
        num_epochs: è®­ç»ƒè½®æ•°
        device: ä½¿ç”¨çš„è®¾å¤‡
        save_dir: æ¨¡å‹ä¿å­˜ç›®å½•

    è¿”å›:
        history: åŒ…å«è®­ç»ƒå†å²çš„å­—å…¸
    """
    if device is None:
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    start_time = time.time()
    model = model.to(device)

    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': [],
        'epoch_times': []
    }

    best_val_acc = 0.0

    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(save_dir, exist_ok=True)

    bar=st.empty()

    for epoch in range(num_epochs):
        epoch_start = time.time()
        print(f"Epoch {epoch+1}/{num_epochs}")

        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            loss.backward()
            optimizer.step()

            # ç»Ÿè®¡
            train_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()

        bar.progress(epoch/num_epochs,f"Epoch {epoch + 1}/{num_epochs}")

        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        train_loss = train_loss / len(train_loader.sampler)
        train_acc = train_correct / train_total

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for inputs, labels in valid_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                # å‰å‘ä¼ æ’­
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                # ç»Ÿè®¡
                val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        # è®¡ç®—éªŒè¯æŒ‡æ ‡
        val_loss = val_loss / len(valid_loader.sampler)
        val_acc = val_correct / val_total

        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler:
            scheduler.step()

        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)

        # è®°å½•æ¯ä¸ªepochçš„æ—¶é—´
        epoch_end = time.time()
        epoch_time = epoch_end - epoch_start
        history['epoch_times'].append(epoch_time)

        filename=f"{save_dir}/{model.__class__.__name__}_best({recorder}).pth"

        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜æƒé‡
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), filename)
            print(f"æ¨¡å‹å·²ä¿å­˜åˆ° {filename}")
            st.success(f"æ¨¡å‹å·²ä¿å­˜åˆ° {filename}")

        print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}")
        print(f"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
        print(f"æœ¬è½®ç”¨æ—¶: {epoch_time:.2f}s")
        print("-" * 50)
        st.success(f"Epoch {epoch + 1}/{num_epochs}"+f"è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}\n"+f"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}\n"+f"æœ¬è½®ç”¨æ—¶: {epoch_time:.2f}s")

    # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
    total_time = time.time() - start_time
    print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f}s")

    return model, history

def evaluate_model(model, test_loader, criterion, device=None, classes=None, timestamp=None):
    """
    è¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½

    å‚æ•°:
        model: è¦è¯„ä¼°çš„æ¨¡å‹
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        device: ä½¿ç”¨çš„è®¾å¤‡
        classes: ç±»åˆ«åç§°åˆ—è¡¨

    è¿”å›:
        test_loss: æµ‹è¯•æŸå¤±
        test_acc: æµ‹è¯•å‡†ç¡®ç‡
    """
    if device is None:
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    model = model.to(device)
    model.eval()

    test_loss = 0.0
    test_correct = 0
    test_total = 0

    y_true = []
    y_pred = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # å‰å‘ä¼ æ’­
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # ç»Ÿè®¡
            test_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            test_total += labels.size(0)
            test_correct += (predicted == labels).sum().item()

            # æ”¶é›†çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

    # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
    test_loss = test_loss / len(test_loader.dataset)
    test_acc = test_correct / test_total

    print(f"æµ‹è¯•æŸå¤±: {test_loss:.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")

    # å¦‚æœæä¾›äº†ç±»åˆ«åç§°ï¼Œè®¡ç®—æ··æ·†çŸ©é˜µ
    if classes:
        try:
            from sklearn.metrics import confusion_matrix, classification_report
            import seaborn as sns

            cm = confusion_matrix(y_true, y_pred)
            plt.figure(figsize=(10, 8))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
            plt.xlabel('Predicted')  # è‹±æ–‡æ ‡ç­¾
            plt.ylabel('True')  # è‹±æ–‡æ ‡ç­¾
            plt.title('Confusion Matrix')  # è‹±æ–‡æ ‡é¢˜
            os.makedirs('./reportfig', exist_ok=True)  # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
            plt.savefig(f"./reportfig/{timestamp}_confusion_matrix.png")
            st.pyplot(plt.gcf())

            # æ‰“å°åˆ†ç±»æŠ¥å‘Š
            print("åˆ†ç±»æŠ¥å‘Š:")
            st.write("åˆ†ç±»æŠ¥å‘Š:")
            print(classification_report(y_true, y_pred, target_names=classes))
            st.dataframe(pd.DataFrame(classification_report(y_true, y_pred, target_names=classes, output_dict=True)).transpose())

        except ImportError:
            st.error("è­¦å‘Š: æœªå®‰è£…sklearnæˆ–seabornï¼Œæ— æ³•ç”Ÿæˆæ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Š")

    return test_loss, test_acc

def plot_training_history(history, title="Training History"):
    """
    ç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿

    å‚æ•°:
        history: åŒ…å«è®­ç»ƒå†å²çš„å­—å…¸
        title: å›¾è¡¨æ ‡é¢˜
    """
    plt.figure(figsize=(12, 5))

    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Training Loss')  # è‹±æ–‡æ ‡ç­¾
    plt.plot(history['val_loss'], label='Validation Loss')  # è‹±æ–‡æ ‡ç­¾
    plt.xlabel('Epochs')  # è‹±æ–‡æ ‡ç­¾
    plt.ylabel('Loss')  # è‹±æ–‡æ ‡ç­¾
    plt.title('Loss Curves')  # è‹±æ–‡æ ‡é¢˜
    plt.legend()

    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='Training Accuracy')  # è‹±æ–‡æ ‡ç­¾
    plt.plot(history['val_acc'], label='Validation Accuracy')  # è‹±æ–‡æ ‡ç­¾
    plt.xlabel('Epochs')  # è‹±æ–‡æ ‡ç­¾
    plt.ylabel('Accuracy')  # è‹±æ–‡æ ‡ç­¾
    plt.title('Accuracy Curves')  # è‹±æ–‡æ ‡é¢˜
    plt.legend()

    plt.suptitle(title)  # è‹±æ–‡æ€»æ ‡é¢˜
    plt.tight_layout()
    os.makedirs('./reportfig', exist_ok=True)  # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
    plt.savefig(f"./reportfig/{title.replace(' ', '_')}.png")
    st.pyplot(plt.gcf())

def visualize_model_predictions(model, test_loader, classes, device=None, num_images=25, title="visualize predictions"):
    """
    å¯è§†åŒ–æ¨¡å‹é¢„æµ‹

    å‚æ•°:
        model: è¦è¯„ä¼°çš„æ¨¡å‹
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        classes: ç±»åˆ«åç§°åˆ—è¡¨
        device: ä½¿ç”¨çš„è®¾å¤‡
        num_images: è¦æ˜¾ç¤ºçš„å›¾åƒæ•°é‡
    """
    if device is None:
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    model = model.to(device)
    model.eval()

    # è·å–batchæ•°æ®
    images, labels = next(iter(test_loader))

    with torch.no_grad():
        outputs = model(images.to(device))
        _, preds = torch.max(outputs, 1)

    # å°†é¢„æµ‹å’Œæ ‡ç­¾è½¬æ¢ä¸ºCPUä¸Šçš„numpyæ•°ç»„
    preds = preds.cpu().numpy()
    labels = labels.numpy()

    # è®¡ç®—display_gridçš„å°ºå¯¸
    grid_size = int(np.ceil(np.sqrt(num_images)))
    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))

    for i, ax in enumerate(axes.flat):
        if i < min(num_images, len(preds)):
            img = images[i].numpy().transpose((1, 2, 0))
            # åæ ‡å‡†åŒ–
            mean = np.array([0.4914, 0.4822, 0.4465])
            std = np.array([0.2023, 0.1994, 0.2010])
            img = std * img + mean
            img = np.clip(img, 0, 1)

            ax.imshow(img)
            color = "green" if preds[i] == labels[i] else "red"
            ax.set_title(f"Predicted: {classes[preds[i]]}\nTrue: {classes[labels[i]]}", color=color)  # è‹±æ–‡æ ‡ç­¾
        ax.axis('off')

    plt.tight_layout()
    os.makedirs('./reportfig', exist_ok=True)  # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
    plt.savefig(f"./reportfig/{title.replace(' ', '_')}.png")
    st.pyplot(plt.gcf())

def visualize_conv_filters(model, layer_name='conv1', title="visualize filters"):
    """
    å¯è§†åŒ–å·ç§¯æ ¸

    å‚æ•°:
        model: æ¨¡å‹
        layer_name: è¦å¯è§†åŒ–çš„å·ç§¯å±‚åç§°
    """
    model.eval()

    # è·å–æŒ‡å®šå±‚çš„æƒé‡
    for name, module in model.named_modules():
        if name == layer_name and isinstance(module, nn.Conv2d):
            weights = module.weight.data.clone().cpu()
            break
    else:
        print(f"æœªæ‰¾åˆ°åä¸º {layer_name} çš„å·ç§¯å±‚")
        return

    # è§„èŒƒåŒ–æƒé‡ä»¥ä¾¿å¯è§†åŒ–
    weights = weights - weights.min()
    weights = weights / weights.max()

    # ç»˜åˆ¶å·ç§¯æ ¸
    num_filters = min(16, weights.size(0))
    fig, axes = plt.subplots(4, 4, figsize=(10, 10))
    fig.suptitle(f'Conv Layer {layer_name} Filters')  # è‹±æ–‡æ ‡é¢˜

    for i, ax in enumerate(axes.flat):
        if i < num_filters:
            # å¦‚æœæ˜¯3é€šé“çš„å·ç§¯æ ¸ï¼Œç›´æ¥æ˜¾ç¤ºRGB
            if weights.size(1) == 3:
                ax.imshow(weights[i].permute(1, 2, 0))
            else:
                # å¦‚æœä¸æ˜¯3é€šé“ï¼Œåªæ˜¾ç¤ºç¬¬ä¸€ä¸ªé€šé“
                ax.imshow(weights[i, 0], cmap='viridis')
        ax.axis('off')

    plt.tight_layout()
    os.makedirs('./reportfig', exist_ok=True)  # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
    plt.savefig(f"./reportfig/{title.replace(' ', '_')}.png")
    st.pyplot(plt.gcf())

def model_complexity(model, input_size=(3, 48, 48), batch_size=128, device=None):
    """
    è®¡ç®—æ¨¡å‹å‚æ•°é‡å’Œæ¨ç†æ—¶é—´

    å‚æ•°:
        model: è¦è¯„ä¼°çš„æ¨¡å‹
        input_size: è¾“å…¥å°ºå¯¸
        batch_size: æ‰¹é‡å¤§å°
        device: ä½¿ç”¨çš„è®¾å¤‡

    è¿”å›:
        num_params: å‚æ•°é‡
        inference_time: æ¯æ‰¹æ¬¡æ¨ç†æ—¶é—´
    """
    if device is None:
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    model = model.to(device)
    model.eval()

    # è®¡ç®—å‚æ•°é‡
    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    # åˆ›å»ºéšæœºè¾“å…¥
    dummy_input = torch.randn(batch_size, *input_size).to(device)

    # é¢„çƒ­
    with torch.no_grad():
        for _ in range(10):
            _ = model(dummy_input)

    # è®¡æ—¶
    start_time = time.time()
    with torch.no_grad():
        for _ in range(100):
            _ = model(dummy_input)
    end_time = time.time()

    inference_time = (end_time - start_time) / 100

    print(f"å‚æ•°é‡: {num_params:,}")
    print(f"æ¯æ‰¹æ¬¡({batch_size}ä¸ªæ ·æœ¬)æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms")
    st.success("å·²åˆ†ææ¨¡å‹å¤æ‚åº¦"+'\n'+f"å‚æ•°é‡: {num_params:,}"+'\n'+f"æ¯æ‰¹æ¬¡({batch_size}ä¸ªæ ·æœ¬)æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms")

    return num_params, inference_time


def predict(image, model, device=None):
    emotion_mapping = {0: 'Angry ğŸ˜ ', 1: 'Disgust ğŸ˜£', 2: 'Fear ğŸ˜±', 3: 'Happy ğŸ˜€', 4: 'Sad ğŸ˜¢', 5: 'Surprise ğŸ˜²',
                       6: 'Neutral ğŸ˜'}
    '''
    klï¼šæ€»ä¹‹å°±æ˜¯çªå‘å¥‡æƒ³å°†å…¶æ”¾è¿›å¤´æ–‡ä»¶äº†
    æˆ‘ç”¨åˆ°å¹¶évitæ¨¡å‹ï¼Œæ˜¯å—ï¼Ÿ
    '''
    if device is None:
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')


    model = model.to(device)
    model.eval()

    image = image.to(device)
    image = image.unsqueeze(0)

    logits = model(image)
    st.write(logits)

    y_prob = torch.nn.functional.softmax(logits[0], dim=-1)

    df_result = pd.DataFrame(
        y_prob.T.cpu().detach().numpy(),
        columns=['Probability'],
        index=emotion_mapping.values()
    )

    return df_result